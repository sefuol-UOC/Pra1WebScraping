{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"float: left; width: 50%;\">\n",
    "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "</div>\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.851 · Tipología y ciclo de vida de los datos · PRA1</p>\n",
    "<p style=\"margin: 0; text-align:right;\">2020-2 · Máster universitario en Ciencia de datos (Data science)</p>\n",
    "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
    "</div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>\n",
    "\n",
    "\n",
    "# Práctica 1: Web scraping\n",
    "\n",
    " - **https://github.com/sfunesolaria/Pra1WebScraping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covid code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double spiders\n",
    "\n",
    "class data_spider(scrapy.Spider):\n",
    "    name = 'data_spider'\n",
    "\n",
    "    found_events = []\n",
    "\n",
    "    def search_url_generator(n_results):\n",
    "        \"\"\" Get all results URLs from selected search\n",
    "    \n",
    "        n_results (int) -- Number of total results in search\n",
    "        \"\"\"\n",
    "        skip_articles = [str(ini) for ini in range(0, n_results, 25)]\n",
    "        links = []\n",
    "        for skip in skip_articles:\n",
    "            link = 'https://export.arxiv.org/find/all/1/'\n",
    "            link += 'abs:+AND+vaccines+OR+EXACT+COVID_19+EXACT+SARS_COV-2'\n",
    "            link += '/0/1/0/all/0/1?'\n",
    "            link += 'skip=' + skip\n",
    "            links.append(link)\n",
    "        return links\n",
    "\n",
    "    start_urls = search_url_generator(266)\n",
    "    base_url = 'https://export.arxiv.org'\n",
    "    \n",
    "    def parse(self, response):\n",
    "        # Get all links in search page\n",
    "        for link in response.xpath('//span[@class=\"list-identifier\"]'):\n",
    "            links = {}\n",
    "            rel_url = str(link.xpath('.//a/@href').extract_first())\n",
    "            url = data_spider.base_url + rel_url\n",
    "            yield scrapy.Request(url, callback=self.parse2)\n",
    "\n",
    "\n",
    "    def parse2(self, response):\n",
    "        # Get elements of interest in article page and store\n",
    "        for event in response.xpath('//div[contains(@class, \"leftcolumn\")]'):\n",
    "            event_details = dict()\n",
    "\n",
    "            event_details['id'] = event.xpath('div[contains(@class, \"metatable\")]/table/tr/td[contains(@class, \"tablecell arxivid\")]/a/text()').extract_first()\n",
    "\n",
    "            event_details['category_code'] = event.xpath('div[contains(@class, \"metatable\")]/table/tr/td[contains(@class, \"tablecell arxivid\")]/span/a/following-sibling::text()').extract_first()\n",
    "            \n",
    "            event_details['category'] = event.xpath('div[contains(@class, \"subheader\")]/h1/text()').extract_first()\n",
    "            \n",
    "            event_details['title'] = event.xpath('h1[contains(@class, \"title mathjax\")]/span/following-sibling::text()').extract_first()\n",
    "\n",
    "            event_details['date'] = event.xpath('div[contains(@class, \"dateline\")]/text()').extract_first().replace(\"\\n\", \"\").strip()\n",
    "            \n",
    "            event_details['author_1'] = event.xpath('div[contains(@class, \"authors\")]/a[1]/text()').extract_first()\n",
    "\n",
    "            event_details['author_2'] = event.xpath('div[contains(@class, \"authors\")]/a[2]/text()').extract_first()\n",
    "            \n",
    "            event_details['author_3'] = event.xpath('div[contains(@class, \"authors\")]/a[3]/text()').extract_first()\n",
    "            \n",
    "            event_details['author_4'] = event.xpath('div[contains(@class, \"authors\")]/a[4]/text()').extract_first()\n",
    "            \n",
    "            event_details['author_5'] = event.xpath('div[contains(@class, \"authors\")]/a[5]/text()').extract_first()\n",
    "            \n",
    "            event_details['summary'] = event.xpath('blockquote[contains(@class, \"abstract mathjax\")]/span/following-sibling::text()').extract_first().replace(\"\\n\", \"\").strip()\n",
    "            \n",
    "            event_details['link'] = event.xpath('div[contains(@class, \"metatable\")]/table/tr/td[contains(@class, \"tablecell arxivid\")]/a/@href').extract_first()\n",
    "            \n",
    "            self.found_events.append(event_details)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process = CrawlerProcess({\n",
    "        'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)',\n",
    "        'LOG_LEVEL': 'ERROR'})\n",
    "    process.crawl(data_spider)\n",
    "    process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset into csv\n",
    "\n",
    "dataset = data_spider.found_events\n",
    "keys = dataset[0].keys()\n",
    "\n",
    "try:\n",
    "    with open(\"dataset_covid.csv\", 'w', newline='', encoding=\"utf-8\") as output_file:\n",
    "        w = csv.DictWriter(output_file, keys, delimiter=';')\n",
    "        w.writeheader()\n",
    "        w.writerows(dataset)\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
